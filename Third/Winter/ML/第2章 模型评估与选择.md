## 2.1 经验误差与过拟合

- 错误率(error rate)
- 精度(accuracy)

- 误差(error)
  - 训练误差(training error)
  - 经验误差(empirical error)
  - 泛化误差(generalization error)

- 过拟合(overfitting)
- 欠拟合(underfitting)

## 2.2 评估方法

### 2.2.1 留出法(hold-out)

### 2.2.2 交叉验证法(cross validation)

特殊情况：留一法(Leave-One-Out, LOO)

### 2.2.3 自助法(Bootstrapping)
$$
lim_{m\to \infty}{{(1 - \frac{1}{m})}^{m}}\to \frac{1}{e} \approx 0.368
$$

## 2.3 性能度量(performance measure)

### 2.3.1 错误率与精度

### 2.3.2 查准率、查全率与F1(precesion, recall, F1)
- 混淆矩阵(confusion matrix)
- 查准率P：$$P = \frac{TP}{TP + FP}$$
- 查全率R：$$R = \frac{TP}{TP + FN}$$
- P-R曲线：若一个算法的P-R曲线被另一个算法的P-R曲线完全包住，则后者的性能优于前者。
- 平衡点(Break-Even Point, BEP)：P-R曲线上查准率与查全率相等的点。
- F1：$$F1 = \frac{2PR}{P + R}$$
- Fβ：
$$F\beta = \frac{(1 + \beta^2)PR}{\beta^2P + R}$$
性质：当β>1时，查全率有更大影响；当β<1时，查准率有更大影响；当β=1时，F1。

### 2.3.3 ROC 与AUC
ROC曲线: 
- 纵轴是“真正例率”(True Positive Rate)$$TPR=\frac{TP}{TP+FN}$$
- 横轴是“假正例率”(False Positive Rate) $$FPR=\frac{FP}{TN+FP}$$
- 若一个学习器的ROC曲线被另一个学习器的曲线完全“包住"则可断言后者的性能优于前者。

AUC

### 2.3.4 代价敏感错误率与代价曲线
为错误赋予“非均等代价”

代价曲线(cost curve)

## 2.4 比较检验
### 2.4.1 假设检验

## 2.5 偏差与方差
偏差-方差窘境(bias-variance dilemma)
- 训练不足，偏差主导泛化错误率
- 随着训练程度加深，方差逐渐主导泛化错误率
